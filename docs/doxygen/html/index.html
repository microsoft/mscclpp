<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MSCCL++: MSCCL++</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MSCCL++
   </div>
   <div id="projectbrief">GPU-driven computation &amp; communication stack</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">MSCCL++ </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a href="https://github.com/microsoft/mscclpp/releases/latest"><object type="image/svg+xml" data="https://img.shields.io/github/release/microsoft/mscclpp.svg" style="pointer-events: none;">Latest Release</object></a> [<object type="image/svg+xml" data="https://img.shields.io/github/license/microsoft/mscclpp.svg" style="pointer-events: none;">License</object>](LICENSE) <a href="https://github.com/microsoft/mscclpp/actions/workflows/codeql-analysis.yml"><object type="image/svg+xml" data="https://github.com/microsoft/mscclpp/actions/workflows/codeql-analysis.yml/badge.svg?branch=main" style="pointer-events: none;">CodeQL</object></a></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Pipelines </th><th class="markdownTableHeadNone">Build Status  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Unit Tests (CUDA) </td><td class="markdownTableBodyNone"><a href="https://dev.azure.com/binyli/HPC/_build/latest?definitionId=4&amp;branchName=main"><img src="https://dev.azure.com/binyli/HPC/_apis/build/status%2Fmscclpp-ut?branchName=main" alt="Build Status" class="inline"/></a>  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Integration Tests (CUDA) </td><td class="markdownTableBodyNone"><a href="https://dev.azure.com/binyli/HPC/_build/latest?definitionId=3&amp;branchName=main"><img src="https://dev.azure.com/binyli/HPC/_apis/build/status%2Fmscclpp-test?branchName=main" alt="Build Status" class="inline"/></a>  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Integration Tests (ROCm) </td><td class="markdownTableBodyNone"><a href="https://dev.azure.com/binyli/HPC/_build/latest?definitionId=7&amp;branchName=main"><img src="https://dev.azure.com/binyli/HPC/_apis/build/status%2Fmscclpp-test-rocm?branchName=main" alt="Build Status" class="inline"/></a>  </td></tr>
</table>
<p>A GPU-driven communication stack for scalable AI applications.</p>
<p>See Quick Start to quickly get started.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Overview</h1>
<p>MSCCL++ redefines inter-GPU communication interfaces, thereby delivering a highly efficient and customizable communication stack for distributed GPU applications. Its design is specifically tailored to accommodate diverse performance optimization scenarios often encountered in state-of-the-art AI applications. Figure below provides a high-level overview of MSCCL++ abstractions in CUDA, C, and Python.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><center>MSCCL++ Abstractions Overview  </center></th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><center> <img src="./docs/figs/abstractions.png" alt="MSCCL++ Abstractions" style="width: 800px;" class="inline"/>  </center></td></tr>
</table>
<center>The followings highlight the key features of MSCCL++.</center><center><ul>
<li><b>Light-weight and multi-layer abstractions.</b> MSCCL++ provides communication abstractions at lowest level close to hardware and at the highest level close to application API. The lowest level of abstraction is ultra light weight which enables a user to implement logics of data movement for a collective operation such as AllReduce inside a GPU kernel extremely efficiently without worrying about memory ordering of different ops. The modularity of MSCCL++ enables a user to construct the building blocks of MSCCL++ in a high level abstraction in Python and feed them to a CUDA kernel in order to facilitate the user's productivity.</li>
<li><b>1-sided 0-copy synchronous and asynchronous abstracts.</b> MSCCL++ provides fine-grained synchronous and asynchronous 0-copy 1-sided abstracts for communication primitives such as <code>put()</code>, <code>get()</code>, <code>signal()</code>, <code>flush()</code>, and <code>wait()</code>. The 1-sided abstractions allows a user to asynchronously <code>put()</code> their data on the remote GPU as soon as it is ready without requiring the remote side to issue any receive instruction. This enables users to easily implement flexible communication logics, such as overlapping communication with computation, or implementing customized collective communication algorithms without worrying about potential deadlocks. Additionally, the 0-copy capability enables MSCCL++ to directly transfer data between user's buffers without using intermediate internal buffers which saves GPU bandwidth and memory capacity.</li>
<li><b>Unified abstractions for different interconnection hardware.</b> MSCCL++ provides consistent abstractions regardless of the location of the remote GPU (either on the local node or on a remote node) or the underlying link (either NVLink/xGMI or InfiniBand). This simplifies the code for inter-GPU communication, which is often complex due to memory ordering of GPU/CPU read/writes and therefore, is error-prone.</li>
</ul>
</center><center></center><h1><a class="anchor" id="autotoc_md2"></a>
Performance</h1>
<center> While the power of MSCCL++ is fully realized with application-specific optimization, it still delivers performance benefits even for collective communication operations. The following figures provide a comparison of the AllReduce throughput of MSCCL++ against NCCL 2.19.3. This benchmark was tested over two <a href="https://learn.microsoft.com/en-us/azure/virtual-machines/ndm-a100-v4-series">Azure NDmv4 SKUs</a> (8 A100-80G GPUs per node).</center><center>The key motivation behind these results is scaling of inference for LLM models using tensor parallelism. LLM requests usually are executed in two phases: prompt processing and token sampling. The prompt processing uses a large batch size that is usually equal to a request context length and the corresponding AllReduce size is <code>len_context*dim_hidden*sizeof(fp16)</code>. For a context length of 2048 with a hidden dimension of 12288 (GPT-3 size), the AllReduce size is 48MB. The token sampling uses a smaller batch size which corresponds to concurrent user requests in the system and therefore, the AllReduce size is <code>batch_size*dim_hidden*sizeof(fp16)</code>. For a concurrency of 16 users, the AllReduce size is 384KB. As the figures below demonstrates, MSCCL++ provides significant speed up over NCCL which is crucial for efficiency of serving LLMs at large scale.</center><center><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><center>Single-node AllReduce </center></th><th class="markdownTableHeadNone"><center> <center>Two-node AllReduce  </center></center></th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><center><center> <img src="./docs/figs/mscclpp_vs_nccl_comparison_num_nodes_1.jpeg" alt="MSCCL++ vs NCCL AllReduce (Single-node)" style="width: 400px;" class="inline"/> </center></center></td><td class="markdownTableBodyNone"><center><center> <img src="./docs/figs/mscclpp_vs_nccl_comparison_num_nodes_2.jpeg" alt="MSCCL++ vs NCCL AllReduce (Two-node)" style="width: 400px;" class="inline"/>  </center></center></td></tr>
</table>
</center><center><center><center></center></center></center><h1><a class="anchor" id="autotoc_md3"></a>
Key Concepts</h1>
<center><center><center> The following highlights key concepts of MSCCL++.</center></center></center><center><center><center></center></center></center><h2><a class="anchor" id="autotoc_md4"></a>
On-GPU Communication Interfaces: Channels</h2>
<center><center><center> MSCCL++ provides peer-to-peer communication methods between GPUs. A peer-to-peer connection between two GPUs is called a <em>Channel</em>. Channels are constructed by MSCCL++ host-side interfaces and copied to GPUs during initialization. Channels provide <em>GPU-side interfaces</em>, which means that all communication methods are defined as a device function to be called from a GPU kernel code. For example, the <code>put()</code> method in the following example copies 1KB data from the local GPU to a remote GPU.</center></center></center><center><center><center><div class="fragment"><div class="line"><span class="comment">// `ProxyChannel` will be explained in the following section.</span></div>
<div class="line">__device__ <a class="code" href="namespacemscclpp.html#ad527fb55e019c2b79a09d5be24c81aa6">mscclpp::DeviceHandle&lt;mscclpp::SimpleProxyChannel&gt;</a> channel;</div>
<div class="line">__global__ <span class="keywordtype">void</span> gpuKernel() {</div>
<div class="line">  ...</div>
<div class="line">  <span class="comment">// Only one thread is needed for this method.</span></div>
<div class="line">  channel.put(<span class="comment">/*dstOffset=*/</span> 0, <span class="comment">/*srcOffset=*/</span> 0, <span class="comment">/*size=*/</span> 1024);</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --></center></center></center><center><center><center>MSCCL++ also provides efficient synchronization methods, <code>signal()</code>, <code>flush()</code>, and <code>wait()</code>. For example, we can implement a simple barrier between two ranks (peer-to-peer connected through <code>channel</code>) as follows. Explanation of each method is inlined.</center></center></center><center><center><center><div class="fragment"><div class="line"><span class="comment">// Only one thread is needed for this function.</span></div>
<div class="line">__device__ <span class="keywordtype">void</span> barrier() {</div>
<div class="line">  <span class="comment">// Inform the peer GPU that I have arrived at this point.</span></div>
<div class="line">  channel.signal();</div>
<div class="line">  <span class="comment">// Flush the previous signal() call, which will wait for completion of signaling.</span></div>
<div class="line">  channel.flush();</div>
<div class="line">  <span class="comment">// Wait for the peer GPU to call signal().</span></div>
<div class="line">  channel.wait();</div>
<div class="line">  <span class="comment">// Now this thread is synchronized with the remote GPUâ€™s thread.</span></div>
<div class="line">  <span class="comment">// Users may call a local synchronize functions (e.g., __syncthreads())</span></div>
<div class="line">  <span class="comment">// to synchronize other local threads as well with the remote side.</span></div>
<div class="line">}</div>
</div><!-- fragment --></center></center></center><center><center><center>MSCCL++ provides consistent interfaces, i.e., the above interfaces are used regardless of the location of the remote GPU (either on the local node or on a remote node) or the underlying link (either NVLink/xGMI or InfiniBand).</center></center></center><center><center><center></center></center></center><h2><a class="anchor" id="autotoc_md5"></a>
ProxyChannel and SmChannel</h2>
<center><center><center> MSCCL++ delivers two types of channels, <b>ProxyChannel</b> and <b>SmChannel</b>. <code>ProxyChannel</code> provides (R)DMA-based data copy and synchronization methods. When called, these methods send/receive a signal to/from a host-side proxy (hence the name <code>ProxyChannel</code>), which will trigger (R)DMA (such as <code>cudaMemcpy*</code> or <code>ibv_post_send</code>) or issue synchronization methods (such as <code>cudaStreamSynchronize</code> or <code>ibv_poll_cq</code>). Since the key functionalities are run by the proxy, <code>ProxyChannel</code> requires only a single GPU thread to call its methods. See all <code>ProxyChannel</code> methods from <a href="./include/mscclpp/proxy_channel_device.hpp">here</a>.</center></center></center><center><center><center>On the other hand, <code>SmChannel</code> provides memory-mapping-based copy and synchronization methods. When called, these methods will directly use GPU threads to read/write from/to the remote GPU's memory space. Comparing against <code>ProxyChannel</code>, <code>SmChannel</code> is especially performant for low-latency scenarios, while it may need many GPU threads to call copying methods at the same time to achieve high copying bandwidth. See all <code>SmChannel</code> methods from <a href="./include/mscclpp/sm_channel_device.hpp">here</a>.</center></center></center><center><center><center></center></center></center><h2><a class="anchor" id="autotoc_md6"></a>
Host-Side Communication Proxy</h2>
<center><center><center> MSCCL++ provides a default implementation of a host-side proxy for ProxyChannels, which is a background host thread that busy polls triggers from GPUs and conducts functionalities accordingly. For example, the following is a typical host-side code for MSCCL++.</center></center></center><center><center><center>```cpp // Bootstrap: initialize control-plane connections between all ranks auto bootstrap = std::make_shared&lt;mscclpp::TcpBootstrap&gt;(rank, world_size); // Create a communicator for connection setup <a class="el" href="classmscclpp_1_1Communicator.html">mscclpp::Communicator</a> comm(bootstrap); // Setup connections here using <code>comm</code> ... // Construct the default proxy <a class="el" href="classmscclpp_1_1ProxyService.html" title="Proxy service implementation.">mscclpp::ProxyService</a> proxyService(); // Start the proxy proxyService.startProxy(); // Run the user application, i.e., launch GPU kernels here ... // Stop the proxy after the application is finished proxyService.stopProxy(); <div class="fragment"><div class="line">While the default implementation already enables any kinds of communication, MSCCL++ also supports users to easily implement their own customized proxies for further optimization. For example, the following example re-defines how to interpret triggers from GPUs.</div>
<div class="line"> </div>
<div class="line">```cpp</div>
<div class="line">// Proxy FIFO is obtained from mscclpp::Proxy on the host and copied to the device.</div>
<div class="line">__device__ mscclpp::FifoDeviceHandle fifo;</div>
<div class="line">__global__ void gpuKernel() {</div>
<div class="line">  ...</div>
<div class="line">  // Only one thread is needed for the followings</div>
<div class="line">  mscclpp::ProxyTrigger trigger;</div>
<div class="line">  // Send a custom request: &quot;1&quot;</div>
<div class="line">  trigger.fst = 1;</div>
<div class="line">  fifo.push(trigger);</div>
<div class="line">  // Send a custom request: &quot;2&quot;</div>
<div class="line">  trigger.fst = 2;</div>
<div class="line">  fifo.push(trigger);</div>
<div class="line">  // Send a custom request: &quot;0xdeadbeef&quot;</div>
<div class="line">  trigger.fst = 0xdeadbeef;</div>
<div class="line">  fifo.push(trigger);</div>
<div class="line">  ...</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">// Host-side custom proxy service</div>
<div class="line">class CustomProxyService {</div>
<div class="line">private:</div>
<div class="line">  mscclpp::Proxy proxy_;</div>
<div class="line">public:</div>
<div class="line">  CustomProxyService() : proxy_([&amp;](mscclpp::ProxyTrigger trigger) {</div>
<div class="line">                                  // Custom trigger handler</div>
<div class="line">                                  if (trigger.fst == 1) {</div>
<div class="line">                                    // Handle request &quot;1&quot;</div>
<div class="line">                                  } else if (trigger.fst == 2) {</div>
<div class="line">                                    // Handle request &quot;2&quot;</div>
<div class="line">                                  } else if (trigger.fst == 0xdeadbeef) {</div>
<div class="line">                                    // Handle request &quot;0xdeadbeef&quot;</div>
<div class="line">                                  }</div>
<div class="line">                                },</div>
<div class="line">                                [&amp;]() { /* Empty proxy initializer */ }) {}</div>
<div class="line">  void startProxy() { proxy_.start(); }</div>
<div class="line">  void stopProxy()  { proxy_.stop(); }</div>
<div class="line">};</div>
</div><!-- fragment --></center></center></center><center><center><center>Customized proxies can be used for conducting a series of pre-defined data transfers within only a single trigger from GPU at runtime. This would be more efficient than sending a trigger for each data transfer one by one.</center></center></center><center><center><center></center></center></center><h2><a class="anchor" id="autotoc_md7"></a>
Python Interfaces</h2>
<center><center><center> MSCCL++ provides Python bindings and interfaces, which simplifies integration with Python applications.</center></center></center><center><center><center></center></center></center><h1><a class="anchor" id="autotoc_md8"></a>
Contributing</h1>
<center><center><center> This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit <a href="https://cla.opensource.microsoft.com">https://cla.opensource.microsoft.com</a>.</center></center></center><center><center><center>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</center></center></center><center><center><center>This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/">Microsoft Open Source Code of Conduct</a>. For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/">Code of Conduct FAQ</a> or contact <a href="#" onclick="location.href='mai'+'lto:'+'ope'+'nc'+'ode'+'@m'+'icr'+'os'+'oft'+'.c'+'om'; return false;">opencode@microsoft.com</a> with any additional questions or comments.</center></center></center><center><center><center></center></center></center><h1><a class="anchor" id="autotoc_md9"></a>
Trademarks</h1>
<center><center><center> This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow <a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general">Microsoft's Trademark &amp; Brand Guidelines</a>. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies. </center></center></center></div></div><!-- PageDoc -->
</div><!-- contents -->
<div class="ttc" id="anamespacemscclpp_html_ad527fb55e019c2b79a09d5be24c81aa6"><div class="ttname"><a href="namespacemscclpp.html#ad527fb55e019c2b79a09d5be24c81aa6">mscclpp::DeviceHandle</a></div><div class="ttdeci">typename T::DeviceHandle DeviceHandle</div><div class="ttdoc">A type which could be safely used in device side.</div><div class="ttdef"><b>Definition:</b> core.hpp:709</div></div>
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
